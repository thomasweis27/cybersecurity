# Incident Response, Forensics, and Recovery
## 12.1 Incident Response
* Incident: a violation of the policies or procedures
* Events: Some occurrence of something happening. An incident is one option for an event
* Security Incident: A security event with a negative adverse effect on a company
* Incident Response: The action to deal with a security incident
* First Responder: The first person on the scene after a security incident has occurred.
* Central Incident Response Team: Members of the IR team are in one central location and deal with all incidents
* Distributed Incident Response Team: The IR team is spread out across an entire company
* Coordinating Team: A Central Incident Response Team that then communicates with all other teams across all locations
* IR Process:
  * Preparation: Defines roles and responsibilities and develop strategies
  * Identification: First Responders used to figure out what happened, the level of impact, and who else to bring in.
  * Containment: Stop the damage from escalating further and prevent future action
  * Eradication: Taking action to mitigate issues and get the business back up and running
  * Recovery: Everything is eradicated and documented and the business is back to running as normal
  * Documentation & Lessons Learned: Happens after the incident to revisit policies and implement other strategies to help prevent future issues
* IR Team Individuals: Members of management, leadership, information security staff members, and technical experts
  * Legal and HR staff will also be needed to mitigate public appearance/legal issues.
</br></br></br>
* Tabletop Exercise: Talking through the process and making sure that people know how to respond to the threat.
* Walkthrough Exercise: Walk through the response process step-by-step
* Simulated Exercises: Can simulate part/full incident - everyone should know of the simulation to prevent accidental legal actions
* Communication Tests: Makes sure that the parties that need to be reached are reached and backup people are identified
* Partial Exercises: Somewhat intrusive and can disrupt some normal operations
* Full Exercise: Most disruptive to normal business, most useful tests over business continuity and disaster recovery plans.
* Plan Review: Plans, the contact information of users and vendors, site access plans, etc. should be reviewed continuously to ensure readiness.
* Intelligence Lifecycles: Direction, Collection, Processing, Analysis, Dissemination, Feedback
* Cyber Kill Chain:
  * Reconnaissance: researching to understand the target
  * Weaponization: Crafts malware to be used against the target.
  * Delivery: Launch malware against a target
  * Exploitation: Expoits the vulnerability to gain access to the target.
  * Installation: Install backdoors to the target
  * Command and Control (C2): Malware opens a command channel for the attacker to use
  * Actions and Objectives: Accomplish the original goals of the attacker.
* Dimond Model: Grid with four points - Adversary, capabilities, Victim, and infrastructure.
* MITRE: Non-profit Organization with federal funding for research across agencies
  * Common Vulnerabilities and Exposures (CVE) Database
  * Common Weakness Enumeration (CWE) Database
  * ATT&CK framework: to help catalog emerging TTPs (Tactics, Technologies, and procedures) in global attacks.
  * ATT&CK procedures: Initial Access, Execution, Persistence, Privilege Escalation, Defense Evasion, Credential access, lateral movement, Collection, Command and Control, Exfiltration, and Impact.
  * TAXII: Transport protocol allowing the sharing of threat intelligence over HTTPS
  * STIX: Standard format for presenting threat intel info
 
## 12.2 Mitigation of an Incident
* After a security incident, apply mitigation techniques
  * Application Approved Lists (whitelists or allow lists): Companies must review their lists of applications and ensure not used applications are not allowed 
  * Application Deny Lists (Blacklists/block lists): Blocking known bad applications or applications vendors do not want users to access or use bandwidth
  * Quarantine: Anti-virus protection should be set up everywhere and should quarantine possibly dangerous applications/emails
  * Firewall Rules: Check the firewall rules and make sure to block ports, applications, and services that are not needed/potentially dangerous
  * MDM: Revisit MDM policies to ensure issues do not come from the mobile devices entering the workspace.
  * DLP: Revisit the data loss policies and upgrade classifications to data as needed
  * Content/URL Filters: Revisit the content blocked and add/change settings to prevent visitation to these locations.
  * Update or Revoke Certificates: If a certificate is no longer secure/valid, do not use it and revoke the certificate.
  * Isolation: Make sure devices are properly segmented and isolated as needed to prevent issues from spreading. 
  * Segmentation: Ensure networks are properly segmented using VLANs to prevent issues from spreading
  * SOAR: Make sure SOAR IR runbooks and playbooks are up-to-date and ensure the proper steps are taken for data as needed.
    * Runbooks: A set of rules that are mostly automated to respond to threats - these are step-by-step plans for conditions that happen.
    * Playbooks: Step-by-step actions that need to occur within the SOAR process, this is usually done by humans and the playbook is a guide for these users.
   
## 12.3 Log Mamagement
* Gather Data from Vulnerability Scan outputs, SIEM Dashboards, sensor data, and data correlation (combinations of host-based and network-based sensors)
* Sensitivity: Figure out the correct sensitivity for the devices on the network to develop a good baseline.
* Trends: Understand 'normal' data usage for different times and flag events outside of this.
  * Look for trends in antivirus, anti-malware, firewall reports, anti-spam, and system reports
* Alerts: When something is abnormal it is important to alert people that the issue is happening so it can be resolved.
  * Alert Options: Onscreen, email, SMS - different options for different levels of severity.
* Logs: A record kept of actions happening on a network - all organizations should collect, analyze, and preserve security and access logs.
* Firewall logs: Keep track of firewall incidents, and what goes through, and can look for Trojans and other harmful things entering the network.
* System-Level Logs: Events specific to a system or a network of systems including:
  * Login and logout times: The times users connect and disconnect from the network 
  * Login Attempts: If a user is trying to access an account too many times, this could mean hacking is being attempted.
  * Password and account changes: When a user changes their password that should be logged.
  * Privileged-User Events: Events that need elevated privileges should be logged.
  * Assignment of rights, privileges, and permissions: Escalation of privileges for any account should be documented to detect privilege creep.
  * Disabling Accounts: If an account is disabled it should be logged.
  * Deleting Accounts: Removing accounts should be logged.
  * Changes to critical Files and Logs: This should be logged to make sure something is not trying to be covered up.
* Application-level events: File access, error messages, and security violations with apps should be logged.
* User-Level Events: Use of resources, commands and keystrokes, and security violations should be logged to detect abnormalities
* Web Application Firewall (WAF): Firewall for Web applications that can log events of injection, XSS, XSRF/CSRF, and other attacks
* Proxy Logs: Log of data that is being retrieved and who accessed it within the web app.
* DNS LogsL IP addresses making requests to a server should be logged to see frequencies or abnormalities in access. Also, log error messages
* Authentications: To figure out intrusion systems accessed, user authentications should be logged. (login attempts and IP addresses can be really helpful after a security incident.)
* Dump Files: Safed information for data forensics given an event capturing the items in the RAM, error messages on the screen, processes in the background, and log files.
  * This should be collected before going to less volatile data.
* VoIP/SIP: Call data can be logged like numbers, names, and length of calls (not the calls themselves)
* `Syslog`/`rsyslog`/`syslog-ng`: Allows the user to forward logs to a central server for storage and analysis
* `journalctl`: Used to review logs generated by the journal service. (readable format)
* `journalald`: Generates logs in binary formats (computer, nonreadable format)
* NXLog: Open source log collector usable on most OS - collects logs and then forwards them to databases and can back up logs.
* Bandwidth Monitors: Monitors the usage amount of data being used at a given time. Helps establish baselines and find trends. 
* Metadata: Data about data, connected to the data collected itself giving more information during an investigation.
  * Metadata examples: Users, timestamps, GPS locations, phone numbers, device data, descriptions, keywords, created and modified dates

## 12.4 Windows Logging
* Event Forwarding: Configure Specific events on a system that can then be forwarded to another system.
* Collector: Host that receives the log events collected. Consolidates these into one view.
* Collector-initiated subscriptions: Collector computer initiates the collection of events from various computers.
* Source-initiated subscriptions: Initiate the collection of events.
* Windows Event Subscriptions: After the source of the collector has been properly prepared the subscriptions are used to transfer events.
  * Source-Initiated subscriptions: Configure the source computers to forward events to the collector computer.
  * Subscription Configuration: Specify a subscription name, destination log, type, computer or group, and criteria for selecting events to forward.
  * Type of Service Account: Default machine group or specific user service account.
  * Event saving: By default, events are saved in the forwarded Events Log
  * Filters: Without filters, all events are collected
  * Runtime Status: Verifies links to subscriptions
 
## 12.5 Digital Forensics
* Legal Hold: A formal notice to all employees where litigation is imminent. Instruct employees to retain electronically stored information.
* Videos: Must be proved to be unmanipulated to be used in court.
* Admissability: Evidence must be made legally, have an unbroken chain of custody, and be relevant.
* Chain of custody: A record of handling of the gathered evidence. Records of who had evidence from when it was gathered to when it was presented in court.
* Timeline of Events: Needed for admissibility, shows timeframe and order.
* Timestamps: Exact date and time of events for all data, network traffic, and messages - it must be accurate and monitored by a server.
* Time offset: Using Greenwich Mean Time (GMT) if the incident happened in many places - times are displayed with +## to dignify the amount of hours difference depending on what time zone the event happened in.
* Tagging: Including all devices, servers, and even cables that were used in the attack.
* Reports: All findings, are legally appropriate, use an attorney, and should be self-contained.
* Event Logs: The device produces logs, the log must record the date, process, application, and protocol
  * Never use live logs/images, but make a copy, hash to prove that it's the same, and use the hashed version.
* Interviews: follow proper procedure, video or audio recordings, and obey all laws when interviewing.
</br></br></br>
* Order of Volatility: Data that is volatile should be preserved first, then persistent data - gather as much data as possible
  * RAM: Data clears when shut down
  * Swap Files/Page Files: Virtual Extention of RAM (set in OS by default)
  * Hard Drive: Non-volatile data storage
  * Remote Logs: Logs that are not on the hard drive
  * Archived Data: Stored data that is not regularly needed
* Disks: Evidence with recoverable deleted files, requires a sector-by-sector copy
* Firmware: Controls hardware, read-only non-volatile memory, difficult to acquire
* Snapshot: Used on a running system, captures the exact state of the machine, used for future examination
* Cache: sorted data to improve speed, resolution protocols, ARP, and browser caches.
* Artifacts: Some objects with forensic value
* Forensic Acquisition of Data, data gathering tools (imaging software, data extraction tools, advanced search)
* Data Gathering Tools:
  * dd-CLI: used for copying files
  * Memdump: creating a bit-for-bit copy of the hard drive. 
  * WinHex: Inspecting a computer's RAM
* FTK Imager: A tool that lets the investigator acquire, preview, and copy data thoroughly and forensically
* Autopsy: A forensic tool that investigators use to thoroughly examine all data to see exactly what happened.
* Right-to-Audit Clauses: Essential part of contracts including notification, frequency, process, and sanctions for non-compliance.
  * Location of data must be provided as this determines laws with the data
* Data Breach Notification Laws: Laws stating if there was a data breach how long the company has to notify their users.
* Data integrity: Fundamental to security, must be proven, create procedures for integrity.
* Hashing: A way to encrypt data, prove that data is not changed, and state the type of encryption
* Checksums: Hash value used as a checksum, forensic copy needed to be exact, different values means not usable
* Provenance: Demonstrated that digital evidence was gathered at the origin of the data, proving the origin (not proven means no value)

## 12.6 File and Packet Manipulation
* Linux Commands for file manipulation:
  * `cat`: displays the content of the file/files
  * `Head`: lists the first 10 (or specified #) of lines in a file
  * `tail`: lists the last 10 (or specified #) of lines in a file
  * `chmod`: assign special permissions to a file/directory
  * `grep`: search through a file for a specified character string
  * `logger`: lets you add entries to a system log file
* Shell: a program that connects to the OS via the command line terminal allowing for interaction without a GUI
* Scripting: Refers to writing automated programs with command line tasks (usually in Bash or Python)
* Secure Shell (SSH): a remote admin protocol for remote connections
* PuTTY: Open source software supporting SSH and Telnet
* OpenSSL: Encryption standard, open source, creates key pair, uses KPI, and the client uses public key
* Windows Power Shell: Writes scripts, manages services, controls printers and queues, and works with Windows registry and AD.
* Python: Object-oriented language often used for scripting, general purpose for web apps, data science, and ML, and has extensive plug-in libraries
* Packet Capture: Collecting Layer 3 information over the wire/wireless
* TCPDump: Linux tool for collecting packets of data and stored for later analysis
* Wireshark: Network protocol analyzer
* TCPReplay: Used to simulate replay attacks

## 12.7 Redundancy
* Fault Tolerance: The ability to respond to some hardware/software failure without loss of data or operation
* Redundancy: Method for fault tolerance by creating duplicates to store/perform the same function
* Multipath: Machine with many paths between a CPU and a mass-storage appliance.
* Load balancers: spit the load between many systems that do the same function - therefore increasing availability, and providing power.
* NIC Teaming: combine many network cards into a single virtual network
* Redundant NICs: ensure connectivity in situations where system availability is needed and many systems cannot be reasonably used.
* Power redundancy: Generators, or power distribution units to ensure power even in times of issue
* Site redundancy: Hot, warm, and cold sites in different places in the world in case a disaster wipes one away
</br></br></br>
* Redundant Array of Inexpensive Disks (RAID): Copy or mirror data to ensure that corrupted data is not fully lost (parity)
* Raid 0: Stripping: Data is spread across all drives in the array. Faster to write to many devices, but not fault tolerant.
* Raid 1: Mirroring: Data is copied to another drive/drives - high read speeds but 2x the storage and slow writes
* RAID 1+0: A stripe of Mirrors: Data is striped across two+ drives and then mirrored into the same number of drives. Combines benefits of RAID 0 and RAID 1
* RAID 0+1: A mirror of stripes: Creates stripes, and then mirrored - can withstand two failures of the same group.
* RAID 5: Stripping with Parity: Data is striped across drives in addition to parity (checksums) stores on drives too - data writes are slow
* RAID 6: Like RAID 5 but parity is stored on a separate drive. - more than one drive can fail at a time
* Clustering: Redundant processing nodes close to one another providing increased performance, availability, redundancy, and scalability
  * Virtual IP: An IP that is used by many endpoints so data can go to different servers as needed
  * Common Address Redundancy Protocol (CARP): Enables a node to 'own' a virtual IP and respond to connections
  * Active/Passive Load Balancing: One load device working and the second listening to see if the machine fails and it must take the load - work in tandem to distribute network traffic. 
  * Storage Area Network: a high-speed network of storage devices
  * High Avalibity Clusters: Clustering provides high availability and redundancy.
  * Load Balancer: a process distributing processing among multiple nodes.
  * Cluster Linking:
    * Loosly Linked: Systems operate autonomously and in conjunctions - hardware can be different
    * Tightly Linked: Functions as one system, pooling resources. - hardware must be the same
   
## 12.8 Backup and Restore
* 3 - 2 - 1 Rule: 3 copies, 2 on-site, 1 off-site
* Full Backup: Backup that captures all the data on a machine
* Incremental Backup: A backup containing the changes done since the last backup (incremental or full, whatever is the most recent)
* Differential Backup: A backup containing all changes since the last full backup
* SnapShot: An instant copy of a computer (usually a VM) where changes might need to be reverted to
* NAS: Network storage Appliance often used to store backups/other files
* SAN: Network of fast storage appliances - good if data needs to be accessed quickly
* Offsite Storage: Location where the files are stored away from the physical office space/creation space of the data
* Scalability: The ability to increase/decrease storage space
* Restoration Order: Pre-planned order of what servers will be restored after an incident - determined by the importance of data on a server to the company
* Online: accessible by network and quickly accessible
* Offline: separate from the network in case of hacking
  * both offline and online should be used
* Replication and Journaling: The data protecting method ensures data availability and integrity are maintained with multiple copies and tracking data changes.
* Database Mirroring: Data from one database is mirrored onto a separate, backup database.
* SAN replication: duplicates data from one SAN to a backup SAN in real time to provide redundancy, protection against hardware failures, or corruption
* VM Replication: Replicating VMs which can be reverted in case of issue/corruption
* Data Destruction: Asset Disposal, sanitation, destruction, and certification
